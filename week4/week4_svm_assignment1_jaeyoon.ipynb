{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1. Multiclass SVM 구현\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제에 필요한 기본적 패키지와 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#IRIS 데이터 로드\n",
    "iris =  sns.load_dataset('iris') \n",
    "X= iris.iloc[:,:4] #학습할데이터\n",
    "y = iris.iloc[:,-1] #타겟\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 우리가 아는 iris 데이터이다. 이후 svm모델링을 진행하기 위해서 train과 test set으로 데이터를 분리해준다. 여기서는 test size를 20%로 진행했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #test/train 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110     virginica\n",
       "69     versicolor\n",
       "148     virginica\n",
       "39         setosa\n",
       "53     versicolor\n",
       "          ...    \n",
       "64     versicolor\n",
       "91     versicolor\n",
       "81     versicolor\n",
       "51     versicolor\n",
       "0          setosa\n",
       "Name: species, Length: 120, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원할한 분석을 위하여 scaler를 통해 데이터 전처리를 진행한다. scaler는 standardscaler를 사용했다. train데이터에 대해서는 fit_transform을, test 데이터에는 transform만을 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = StandardScaler() #scaling\n",
    "X_train = scal.fit_transform(X_train)\n",
    "X_test = scal.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case 1 : One vs Rest SVM을 이부분에 구현해주세요 위 결과들을 이용해서 multi class SVM을 직접 구현해주세요! 하드코딩이 하시기 편할겁니다.\n",
    "\n",
    "def label(y_train):\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    return y_train\n",
    "\n",
    "def machine(X_train, y_train, c = 5, g = 5):\n",
    "    svcs = []\n",
    "    y_train = label(y_train)\n",
    "    \n",
    "    for i in range(len(y_train.columns)):\n",
    "        svc = SVC(kernel = 'rbf', C = c, gamma = g)\n",
    "        svc.fit(X_train,y_train.iloc[:,i])\n",
    "        svcs.append(svc)\n",
    "        \n",
    "    return svcs\n",
    "\n",
    "def predict(X_test):\n",
    "    \n",
    "    df = pd.DataFrame(index=range(0,len(X_test)))\n",
    "    list_ = []\n",
    "    list_2 = []\n",
    "    \n",
    "    for i in range(len(machine(X_train, y_train, c = 5, g = 5))):\n",
    "        svc = pd.DataFrame(machine(X_train, y_train, c = 5, g = 5)[i].decision_function(X_test))\n",
    "        df = pd.concat([df,svc],axis = 1)\n",
    "    \n",
    "    df_list = df.values.tolist()\n",
    "    \n",
    "    for j in range(len(df_list)):\n",
    "        number = np.argmax(df_list[j])\n",
    "        list_.append(number) \n",
    "    \n",
    "    for k in range(len(list_)):\n",
    "        if list_[k] == 0:\n",
    "            list_2.append(label(y_test).columns[0])\n",
    "        elif list_[k] == 1:\n",
    "            list_2.append(label(y_test).columns[1])\n",
    "        elif list_[k] == 2:\n",
    "            list_2.append(label(y_test).columns[2])\n",
    "                \n",
    "    return list_2    \n",
    "\n",
    "def accuracy(y_test):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print (accuracy_score(y_test,predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본격적으로 위의 방식으로 one vs rest svm을 만들어준다. 가장 근본이 되는 아이디어는 한 분류기는 하나의 class에 대해서만 구분한다는 점이다. 즉, 우리가 사용하는 데이터를 바탕으로 말하자면, versicolor을 구분하는 분류기는 versicolor가 맞는지 아닌지만을 구분한다는 점이다. \n",
    "\n",
    "이를 가능하게 하기 위해서, 범주형 데이터를 더비 변수로 만들어주는 label 함수를 만들어준다. 그리고 machine 함수를 통해 각 label의 class가 맞는지 아닌지를 구분해주는 svm을 만들어준다. for 함수를 통해 만들어진 분류기에 train 데이터를 학습시킨다. 각 분류기들을 리스트 형식으로 return해준다. c,g 값을 5로 설정한 이유는 주어진 과제에서 각각 5라고 제시했기 때문에 이를 따랐다.\n",
    "\n",
    "predict 함수는 위와 같다. 우선 빈 데이터 프레임과 빈 리스트 2개를 만들어준다. 첫번째 for문을 통해 각 분류기의 decision funcion을 데이터 프레임으로 만들어주고, 이를 모두 합쳐 한 행이 각각의 분류기를 통해 얻은 hyperplane과의 거리를 나타내는 데이터 프레임을 만든다. 이 후, 이것을 list로 만들어 앞으로의 계산을 용이하게 한다.\n",
    "(굳이 decision function을 사용한 이유는 sklearn의 문서를 참고했기 때문이다. 자세한 내용은 아래의 링크에 argmax를 찾아 읽어보길 바란다.)\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "거리를 나타내는 list를 argmax 함수를 사용해 가장 큰 값의 인덱스 값이 무엇인지 파악하고 이를 list_에 더해준다. 이후 마지막 for문을 돌려 0일때, 1일때, 2일때 어떤 품종인지를 직접 선언한다. 그리고 이 값을 list_2에 받아준다. 마지막으로 list_2를 return 해주면 분류기를 통해 예측한 값이 나올 것이다.\n",
    "\n",
    "마지막으로 sklearn의 accuracy_score를 사용해, 정확도를 측정할 수 있는 accuracy 함수로 만들어준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SVC(C=5, gamma=5), SVC(C=5, gamma=5), SVC(C=5, gamma=5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine(X_train, y_train, c = 5, g = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'virginica',\n",
       " 'virginica',\n",
       " 'virginica',\n",
       " 'setosa',\n",
       " 'virginica',\n",
       " 'setosa',\n",
       " 'versicolor',\n",
       " 'virginica',\n",
       " 'setosa',\n",
       " 'setosa',\n",
       " 'virginica',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'setosa',\n",
       " 'versicolor',\n",
       " 'virginica',\n",
       " 'virginica',\n",
       " 'setosa',\n",
       " 'virginica',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'virginica',\n",
       " 'setosa',\n",
       " 'setosa',\n",
       " 'virginica',\n",
       " 'virginica',\n",
       " 'versicolor']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 함수를 돌린 값들은 위와 같다. 최종적으로 accuracy(y_test)의 값을 보면 약 0.867의 값이 나왔다. 이 값은 sklearn이 제공하는 svm의 결과와 동일한 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 라이브러리가 제공하는 multi class SVM과 여러분이 구현한 multiclass SVM 결과를 비교해주세요\n",
    "from sklearn.model_selection import train_test_split #데이터셋 분리\n",
    "from sklearn import metrics\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "svm_4 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_4.fit(X_train_2, y_train_2)\n",
    "y_pred = svm_4.predict(X_test_2)\n",
    "\n",
    "metrics.accuracy_score(y_test_2,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
